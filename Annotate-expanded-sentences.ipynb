{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds annotations to the data on Italian negative polarity items (NPI) and their licensors (NEGPOLs)\n",
    "\n",
    "The NPI considered are \"mai\" (ever) \"nessuno\" (no/no one, NPI in object position by NEGPOL in subject position), \"alcunchè\" (anything). The NEGPOLs considered are \"Nessuno\" (No/No one, subject); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "with open(\"ita-negpol-embedded-align-expanded.csv\", 'r') as f:       # \n",
    "    with open(\"ita-negpol-embedded-align-expanded-annotated.csv\", 'w') as o:   # ita-negpol-embedded-align-expanded\n",
    "        f.readline()   # reading the header\n",
    "        o.write(\"ID:|BlockName|Block#|Sentence:|Original:|NPI Present?|NEG-licensing-subject?|Affirmative?|Embedded?|Expected Grammaticality\\n\")\n",
    "        data = f.readlines()\n",
    "        #print(data[0])\n",
    "        for i in data:\n",
    "            parts = i.split('|') \n",
    "            # ID:|BLOCKNAME|INBLOCK#|Sentence:|Original:|Maria|Uno|Nessuno|mai|nessun|già|alcunchè|@@1@@|@@2@@|@@3@@|@@4@@|@@6@@|\n",
    "            code = parts[1]\n",
    "            frase = parts[3]\n",
    "            pattern_originale = parts[4]\n",
    "            Maria = parts[5]\n",
    "            Uno = parts[6]\n",
    "            Nessuno = parts[7]\n",
    "            mai = parts[8]\n",
    "            nessun = parts[9]\n",
    "            già = parts[10]\n",
    "            alcunchè = parts[11]\n",
    "            # embedding0 = parts[12]     not used\n",
    "            #print(\"part12 = %s\" % parts[12])\n",
    "            embedding1_infi = parts[13]\n",
    "            embedding1_fin = parts[14]\n",
    "            affirm = parts[15]\n",
    "            interr = parts[16]\n",
    "            ############################\n",
    "            NPI = \"ANY, at \"*(nessun !=\"\")+str(nessun)+\"EVER, at \"*(mai !=\"\")+str(mai)+\"ANYTHING, at \"*(alcunchè !=\"\")+str(alcunchè)\n",
    "            #\n",
    "            NEGPOL = \"NO at \"*(Nessuno !=\"\")+str(Nessuno)\n",
    "            #\n",
    "            EMBED = \"INFINITIVE, level 1 \"*(embedding1_infi !=\"\")+\"FINITE, level 1\"*(embedding1_fin !=\"\")\n",
    "            #\n",
    "            if affirm and not interr:\n",
    "                AFFIRM = \"Y\"\n",
    "            elif interr:\n",
    "                AFFIRM = \"\"\n",
    "            else:\n",
    "                sys.exit(\"affirm interr clash!\")\n",
    "            if (mai and not NEGPOL and not AFFIRM):\n",
    "               EXPECTED_GRAMMATICALITY = \"OK\"        # Hai mai visto un orso?\n",
    "            elif NPI and NEGPOL and AFFIRM: \n",
    "                EXPECTED_GRAMMATICALITY = \"OK\"       # Non ho visto nessun orso.\n",
    "            elif NPI and not NEGPOL and not AFFIRM and EMBED == \"\":\n",
    "               EXPECTED_GRAMMATICALITY = \"?\"         # Hai visto nessun orso?\n",
    "            elif NPI and NEGPOL and not AFFIRM and embedding1_fin:\n",
    "               EXPECTED_GRAMMATICALITY = \"UNKNOWN\"   \n",
    "            elif NPI and not NEGPOL and AFFIRM:\n",
    "               EXPECTED_GRAMMATICALITY = \"*\"         # Ho visto nessun orso.\n",
    "            else:\n",
    "               EXPECTED_GRAMMATICALITY = \"NKNOWN\"                                                                                                            \n",
    "                                                                                                                           \n",
    "            #print(\"|\".join(parts[:-13])+\"|\"+NPI+\"|\"+NEGPOL+\"|\"+AFFIRM+\"|\"+EMBED+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            o.write(\"|\".join(parts[:-13])+\"|\"+NPI+\"|\"+NEGPOL+\"|\"+AFFIRM+\"|\"+EMBED+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds annotations to the data on Italian relatives with gaps inside conjunction (see the README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "with open(\"ita-rel-coord-island-expanded.csv\", 'r') as f:       # \n",
    "    with open(\"ita-rel-coord-island-expanded-annotated.csv\", 'w') as o:   # ita-negpol-embedded-align-expanded\n",
    "        f.readline()   # reading the header\n",
    "        o.write(\"ID:|BlockName|Block#|Sentence:|Original:|GAP 1 cong.|GAP 2 cong.|EXPECTED_GRAMMATICALITY\\n\")\n",
    "        data = f.readlines()\n",
    "        #print(data[0])\n",
    "        for i in data:\n",
    "            parts = i.split('|') \n",
    "            # ID:|BLOCKNAME|INBLOCK#|Sentence:|Original:|@@1@@|@@2@@|@@3@@\n",
    "            code = parts[1]\n",
    "            frase = parts[3]\n",
    "            pattern_originale = parts[4]\n",
    "            GAP1 = parts[5]\n",
    "            GAP2 = parts[6]\n",
    "            NP  = parts[7]\n",
    "            #print(NP)\n",
    "            ############################\n",
    "            if GAP1 and GAP2 :\n",
    "               EXPECTED_GRAMMATICALITY = \"OK\" \n",
    "            elif NP and not (GAP1 and GAP2):\n",
    "                EXPECTED_GRAMMATICALITY = \"*\"  \n",
    "            elif GAP1 and GAP2:\n",
    "                EXPECTED_GRAMMATICALITY = \"OK\" # Conoscevo il paziente che Maria voleva registrare  e il dottore testare .\n",
    "            elif not NP and GAP1 and not GAP2:\n",
    "                EXPECTED_GRAMMATICALITY = \"??\" # Conoscevo il paziente che Maria voleva registrare  e il dottore testarlo .\n",
    "            else:\n",
    "                EXPECTED_GRAMMATICALITY = \"*\"                                                                                                                                                                                      \n",
    "            #print(\"|\".join(parts[:-4])+\"|\"+GAP1+\"|\"+GAP2+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            o.write(\"|\".join(parts[:-4])+\"|\"+GAP1+\"|\"+GAP2+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            \n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds annotations to the data on Italian wh-interrogatives and affirmative with object gaps inside conjunction (see the README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "with open(\"ita-wh-coord-island-expanded.csv\", 'r') as f:       # \n",
    "    with open(\"ita-wh-coord-island-expanded-annotated.csv\", 'w') as o:   # ita-negpol-embedded-align-expanded\n",
    "        f.readline()   # reading the header\n",
    "        o.write(\"ID:|BlockName|Block#|Sentence:|Original:|GAP 1 cong.|GAP 2 cong.|EMBEDDED?|Interrogative?|NP-filler?|EXPECTED_GRAMMATICALITY\\n\")\n",
    "        data = f.readlines()\n",
    "        #print(data[0])\n",
    "        for i in data:\n",
    "            parts = i.split('|')\n",
    "            NP = EMBEDDED = INTERR = \"\"\n",
    "            # ID:|BLOCKNAME|INBLOCK#|Sentence:|Original:|@@1@@|@@2@@|@@3@@|@@4@@|@@5@@|\n",
    "            code = parts[1]\n",
    "            frase = parts[3]\n",
    "            pattern_originale = parts[4]\n",
    "            GAP1 = parts[5]\n",
    "            GAP2 = parts[6]\n",
    "            NP = \"Y\"*(parts[7] ==\"\") # @@3@@ absent\n",
    "            EMBEDD = \"Y\"*(parts[8] != \"\") # @@4@@ present \n",
    "            INTERR = \"Y\"*(parts[9] == \"\")  # @@5@@ absent\n",
    "            #rint(\"parts8:\"+parts[8]+\"---\"+EMBEDDED)\n",
    "            \n",
    "            \n",
    "            ############################\n",
    "            if INTERR and GAP1 and GAP2:\n",
    "               EXPECTED_GRAMMATICALITY = \"OK\"  # ATB extraction \n",
    "            elif INTERR and NP and not (GAP1 and GAP2):\n",
    "                EXPECTED_GRAMMATICALITY = \"*\"   # Quale paziente Maria voleva registrare  e il dottore testare il malato .\n",
    "            elif INTERR and (not NP) and GAP1 and (not GAP2):\n",
    "                EXPECTED_GRAMMATICALITY = \"??\" # Quale paziente Maria voleva registrare  e il dottore testarlo .\n",
    "            elif INTERR and GAP1 and GAP2:\n",
    "                EXPECTED_GRAMMATICALITY = \"OK\" # Conoscevo il paziente che Maria voleva registrare  e il dottore testare .\n",
    "            elif (not INTERR) and (not GAP1) and (not GAP2):\n",
    "                EXPECTED_GRAMMATICALITY = \"OK\" # Sapevo che Maria voleva registrare l' uomo e il dottore testare il paziente .\n",
    "            elif (not INTERR) and GAP1 and (not GAP2):\n",
    "                EXPECTED_GRAMMATICALITY = \"?\" # Right Node Raising: Sapevo che Maria voleva registrare e il dottore testare il paziente .\n",
    "            else:\n",
    "                EXPECTED_GRAMMATICALITY = \"*\"                                                                                                                                                                                      \n",
    "            #print(\"|\".join(parts[:-6])+  \"|\"+GAP1+\"|\"+GAP2+\"|\"+EMBEDDED+\"|\"+INTERR+\"|\"+NP+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            o.write(\"|\".join(parts[:-6])+\"|\"+GAP1+\"|\"+GAP2+\"|\"+EMBEDD+\"|\"+INTERR+\"|\"+NP+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")   #EMBEDDED\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds annotations to the data on Italian wh-interrogatives with gaps from inside subjects or objects  (see the README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "with open(\"ita-rel-subobj-island-expanded.csv\", 'r') as f:       # \n",
    "    with open(\"ita-rel-subobj-island-expanded-annotated.csv\", 'w') as o:   # \n",
    "        f.readline()   # reading the header\n",
    "        o.write(\"ID:|BlockName|Block#|Sentence:|Original:|GAP Position|EXPECTED_GRAMMATICALITY\\n\")\n",
    "        data = f.readlines()\n",
    "        #print(data[0])\n",
    "        for i in data:\n",
    "            parts = i.split('|')\n",
    "            NP = EMBEDDED = INTERR = \"\"\n",
    "            # ID:|BLOCKNAME|INBLOCK#|Sentence:|Original:|@@1@@|@@2@@|\n",
    "            code = parts[1]\n",
    "            frase = parts[3]\n",
    "            pattern_originale = parts[4]\n",
    "            OBJ = parts[5]\n",
    "            GAP = parts[6] \n",
    "            \n",
    "            ############################\n",
    "            if OBJ:\n",
    "               EXPECTED_GRAMMATICALITY = \"OK\"  # object extraction of the relative 'head'\n",
    "            else:\n",
    "                EXPECTED_GRAMMATICALITY = \"*\"                                                                                                                                                                                      \n",
    "            #print(\"|\".join(parts[:-3])+  \"|\"+GAP+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            o.write(\"|\".join(parts[:-3])+\"|\"+GAP+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds annotations to the data on Italian wh-interrogatives and affirmatives with gaps present or relaced by pronouns or full NPs (see the README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "with open(\"ita-wh-nogap-embedded-align-expanded.csv\", 'r') as f:       # \n",
    "    with open(\"ita-wh-nogap-embedded-align-expanded-annotated.csv\", 'w') as o:   # ita-negpol-embedded-align-expanded\n",
    "        f.readline()   # reading the header\n",
    "        o.write(\"ID:|BlockName|Block#|Sentence:|Original:|Interrogative?|Gap?|Pronominal Filler|Generic NP Filler|Same Animacy Filler|Embedding Level (0-2)|Cleft Wh|# of Intervening Pronouns|# of Intervening Proper Names|Expected Grammaticality|          EXPECTED_GRAMMATICALITY\\n\")\n",
    "        data = f.readlines()\n",
    "        #print(data[0])\n",
    "        for i in data:\n",
    "            parts = i.split('|')\n",
    "            GAP = EMBED = INTERR = FILL_PRO = FILL_OTHER = FILL_ANIM = \"\"\n",
    "            # ID|BLOCKNAME|INBLOCK#|Sentence|Original:|@@@@|@@10@@ |resto       |@@@@questo   |@@1@@questo |cosa       |Chi     |@@@@problema|@@@@candidato|@@1@@Carla|@@1@@lei    \n",
    "            #                                    4     5 gap  6 -lo|7 fillaltro |8 fill-inan  |9 fill-anim |10 Q-inan  |11 Q-an |12 Q-inan-NP|13 Q-anim-NP   |14 Emb0   |15 Emb0-PRO \n",
    "            # |@@1@@lo |@@1@@costui |@@2@@Susanna|@@2@@lei        |@@2@@il  |@@3@@Giulio|@@3@@lui    |@@3@@il  |@@@@?       |@@@@.|\n",
    "            # |16 emb0 |17 emb0-pro |18 emb1     |19 emb1-pro     |20 emb1  |21 emb2    |22 emb2-pro |23 emb2  |24 interr   \n",
    "            code = parts[1] \n",
    "            frase = parts[3]\n",
    "            pattern_originale = parts[4]\n",
    "            GAP = \"Y\"*(parts[5] != \"\") # @@@@ present\n",
    "            FILL_PRO = \"Y\"*(parts[6] != \"\") # @@10@@ present\n",
    "            FILL_OTHER = \"Y\"*(parts[7] != \"\") # \"il resto\"\n",
    "            if parts[8] != \"\": # \"questo problema\"\n",
    "                FILL_ANIM = \"N\"\n",
    "            elif parts[9] != \"\": # \"questo candidato\"\n",
    "                FILL_ANIM = \"Y\"\n",
    "            # Complexity of Wh-element\n",
    "            INTERR = \"Y\"*(parts[24] != \"\") # Question mark present; \"\" == affirmative \n",
    "            if parts[10] != \"\" or parts[11] != \"\": # Chi or Cosa\n",
    "                    Q_PRON = \"Y\"\n",
    "            elif parts[12] != \"\" or parts[13] != \"\": # \"Quale problema/candidato\"\n",
    "                    Q_PRON = \"N\"\n",
    "            else:    # not a question\n",
    "                    Q_PRON = \"\"\n",
    "            # Animacy of Wh-element        \n",
    "            if parts[11] != \"\" or parts[13] != \"\": # Chi or Quale candidato\n",
    "                    Q_ANIM = \"Y\"\n",
    "            elif parts[10] != \"\" or parts[12] != \"\": # \"Quale problema/candidato\"\n",
    "                    Q_ANIM = \"N\"\n",
    "            else:    # not a question\n",
    "                    Q_ANIM = \"\"        \n",
    "            # Embedding\n",
    "            if parts[21] != \"\" or parts[22] != \"\" or parts[23] != \"\": # Level 3 embedding: [ Giulio/lui/il gionalista [S [S]]]\n",
    "                    EMBED = \"2\"\n",
    "            elif parts[18] != \"\" or parts[19] != \"\" or parts[20] != \"\": # Level 2 embedding: [ Susanno/lui/il professore [S]]\n",
    "                    EMBED = \"1\"\n",
    "            else:    # not embedded\n",
    "                    EMBED = \"0\"\n",
    "            # Presence of pronouns\n",
    "            PRON_COUNT = len([x for x in list(map(parts.__getitem__,[15,17,19,22])) if x != \"\"]) # sum of pronouns (lei/lui/colui) present in input, excluding filler\n",
    "             # Presence of proper names\n",
    "            PNAME_COUNT = len([x for x in list(map(parts.__getitem__,[14,18,21])) if x != \"\"]) # sum of proper names (Carla/Susanna/Giulia) present in input\n",
    "            \n",
    "            ############################\n",
    "            if INTERR and GAP:\n",
    "                EXPECTED_GRAMMATICALITY = \"OK\"  # Quale candidato Maria voleva menzionare \n",
    "            elif not INTERR and not GAP:\n",
    "                EXPECTED_GRAMMATICALITY = \"OK\"   # Maria voleva menzionare questo candidato .\n",
    "            else:\n",
    "                EXPECTED_GRAMMATICALITY = \"*\" # Quale candidato Maria voleva menzionare il candidato? , Maria voleva menzionare. etc. \n",
    "            \n",
    "            if (not INTERR) or (FILL_ANIM == \"\"):\n",
    "                SAME_TYPE_FILLER = \"\"\n",
    "            elif FILL_ANIM == Q_ANIM:\n",
    "                SAME_TYPE_FILLER = \"Y\"\n",
    "            else:\n",
    "                SAME_TYPE_FILLER = \"N\"\n",
    "\n",
    "#Interrogative?|Gap?|Pron.Filler?|OtherFiller?|Same Animacy Filler|Embedding Level (0-2)|SImple Wh|# of Intervening Pron.|# of Intervening Proper Names|Expected Grammaticality\\n\")\n",
    "            #print(\"|\".join(parts[:-22])+  \"|\"+INTERR+\"|\"+GAP+\"|\"+FILL_PRO+\"|\"+FILL_OTHER+\"|\"+SAME_TYPE_FILLER+\"|\"+EMBED+\"|\"+Q_PRON+\"|\"+str(PRON_COUNT)+\"|\"+str(PNAME_COUNT)+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            o.write(\"|\".join(parts[:-22])+\"|\"+INTERR+\"|\"+GAP+\"|\"+FILL_PRO+\"|\"+FILL_OTHER+\"|\"+SAME_TYPE_FILLER+\"|\"+EMBED+\"|\"+Q_PRON+\"|\"+str(PRON_COUNT)+\"|\"+str(PNAME_COUNT)+\"|\"+EXPECTED_GRAMMATICALITY+\"|\\n\")\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
